--- mpisetup.f90	2015-08-19 17:19:52.198497000 +0000
+++ mpisetup.f90	2015-08-19 22:01:12.722731000 +0000
@@ -30,7 +30,8 @@
 implicit none
 ! mpi definitions.
 include 'mpif.h'
-integer numproc, nproc
+integer numproc, nproc, numproc_shm, nproc_shm
+integer mpi_comm_shmem, mpi_comm_shmemroot
 integer mpi_status(mpi_status_size)
 integer, public :: mpi_realkind
 
@@ -38,7 +39,8 @@
 
 subroutine mpi_initialize()
 use mpimod, only : mpi_comm_world,npe,mype
-integer ierr
+integer ierr,np,nuse,new_group,old_group,nshmemroot
+integer, dimension(:), allocatable :: useprocs, itasks
 call mpi_init(ierr)
 ! nproc is process number, numproc is total number of processes.
 call mpi_comm_rank(mpi_comm_world,nproc,ierr)
@@ -54,6 +56,40 @@
    print *,'illegal r_kind (must be single or double)'
    call mpi_cleanup()
 endif
+
+! all the rest below only used for LETKF...
+
+! split into shared memory sub communicators.
+CALL MPI_Comm_split_type(MPI_COMM_WORLD, MPI_COMM_TYPE_SHARED, 0, &
+                         MPI_INFO_NULL, mpi_comm_shmem, ierr)
+call MPI_Comm_rank(mpi_comm_shmem, nproc_shm, ierr)
+call MPI_Comm_size(mpi_comm_shmem, numproc_shm, ierr)
+! create communicator involving just root tasks of each shared
+! memory communicator.
+allocate(itasks(numproc)); itasks=0
+if (nproc_shm == 0) itasks(nproc+1) = 1
+call mpi_allreduce(mpi_in_place,itasks,numproc,mpi_integer,mpi_sum,mpi_comm_world,ierr)
+nshmemroot = count(itasks == 1)
+allocate(useprocs(nshmemroot))
+nuse = 0
+do np=0,numproc-1
+   if (itasks(np+1) == 1) then
+     nuse = nuse + 1
+     useprocs(nuse) = np
+   end if
+enddo
+!if (nproc .eq. 0) then
+!   print *,'nshmemroot',nshmemroot,nuse
+!   print *,useprocs
+!endif
+deallocate(itasks)
+call MPI_COMM_GROUP(MPI_COMM_WORLD,old_group,ierr)
+call MPI_GROUP_INCL(old_group,nuse,useprocs,new_group,ierr)
+deallocate(useprocs)
+call MPI_COMM_CREATE(MPI_COMM_WORLD,new_group,mpi_comm_shmemroot,ierr)
+!print *,'ierr from mpi_comm_create',ierr,mpi_comm_shmemroot
+
+
 end subroutine mpi_initialize
 
 subroutine mpi_cleanup()
--- loadbal.f90	2015-08-20 03:45:07.532432000 +0000
+++ loadbal.f90	2015-08-20 15:11:16.137802000 +0000
@@ -239,15 +239,18 @@
    t1 = mpi_wtime()
 end if
 if (letkf_flag) then
-   ! broadcast observation prior ensemble from root one ensemble member at a time.
+   ! bcast entire obs prior ensemble from root task 
+   ! to a single task on each node (the root task of mpi_comm_shmem)
+   ! send one ensemble member at a time.
+   ! the root tasks of mpi_comm_shmem are mpi_comm_shmemroot.
    allocate(buffer(nobstot))
-   ! allocate anal_ob on non-root tasks
-   if (nproc .ne. 0) allocate(anal_ob(nanals,nobstot))
-   ! bcast anal_ob from root one member at a time.
+   if (nproc .ne. 0 .and. nproc_shm == 0) allocate(anal_ob(nanals,nobstot))
    do nanal=1,nanals
-      buffer(1:nobstot) = anal_ob(nanal,1:nobstot)
-      call mpi_bcast(buffer,nobstot,mpi_real4,0,mpi_comm_world,ierr)
-      if (nproc .ne. 0) anal_ob(nanal,1:nobstot) = buffer(1:nobstot)
+      if (nproc == 0) buffer(1:nobstot) = anal_ob(nanal,1:nobstot)
+      if (nproc_shm == 0) then
+         call mpi_bcast(buffer,nobstot,mpi_real4,0,mpi_comm_shmemroot,ierr)
+         anal_ob(nanal,1:nobstot) = buffer(1:nobstot)
+      end if 
    end do
    deallocate(buffer)
 else
--- letkf.F90	2015-08-19 20:54:26.965979864 +0000
+++ letkf.F90	2015-08-19 22:24:25.226700000 +0000
@@ -74,9 +74,10 @@
 !$$$
 
 use mpisetup
+use, intrinsic :: iso_c_binding
 use omp_lib, only: omp_get_num_threads
 use covlocal, only:  taper, latval
-use kinds, only: r_double,i_kind,r_kind,r_single
+use kinds, only: r_double,i_kind,r_kind,r_single,num_bytes_for_r_single
 use loadbal, only: numptsperproc, &
                    indxproc, lnp_chunk, &
                    grdloc_chunk, kdtree_obs2
@@ -134,12 +135,50 @@
 ! kdtree stuff
 type(kdtree2_result),dimension(:),allocatable :: sresults
 type(kdtree2), pointer :: kdtree_grid
+! pointers and variables used for MPI-3 shared memory manipulations.
+real(r_single), pointer, dimension(:,:) :: anal_ob_fp ! Fortran pointer
+type(c_ptr)                             :: anal_ob_cp ! C pointer
+integer disp_unit, shm_win
+integer(MPI_ADDRESS_KIND) :: win_size, nsize
+integer(MPI_ADDRESS_KIND) :: segment_size
 
 !$omp parallel
 nthreads = omp_get_num_threads()
 !$omp end parallel
 if (nproc == 0) print *,'using',nthreads,' openmp threads'
 
+! setup shared memory segment on each node that points to
+! observation prior ensemble.
+! shared window size will be zero except on root task of
+! shared memory group on each node.
+disp_unit = num_bytes_for_r_single ! anal_ob is r_single
+nsize = nobstot*nanals
+if (nproc_shm == 0) then
+   win_size = nsize*disp_unit
+else
+   win_size = 0
+endif
+call MPI_Win_allocate_shared(win_size, disp_unit, MPI_INFO_NULL,&
+                             mpi_comm_shmem, anal_ob_cp, shm_win, ierr)
+if (nproc_shm == 0) then
+   ! create shared memory segment on each shared mem comm
+   call MPI_Win_lock(MPI_LOCK_EXCLUSIVE,0,MPI_MODE_NOCHECK,shm_win,ierr)
+   call c_f_pointer(anal_ob_cp, anal_ob_fp, [nanals, nobstot])
+   ! copy array data into shared memory segment
+   anal_ob_fp = anal_ob
+   call MPI_Win_unlock(0, shm_win, ierr)
+   nullify(anal_ob_fp)
+   ! don't need anal_ob anymore
+   deallocate(anal_ob)
+endif
+! barrier here to make sure no tasks try to access shared
+! memory segment before it is created.
+call mpi_barrier(mpi_comm_world, ierr)
+! associate fortran pointer with c pointer to shared memory 
+! segment (containing observation prior ensemble) on each task.
+call MPI_Win_shared_query(shm_win, 0, segment_size, disp_unit, anal_ob_cp, ierr)
+call c_f_pointer(anal_ob_cp, anal_ob_fp, [nanals, nobstot])
+
 ! define a few frequently used parameters
 r_nanals=one/float(nanals)
 r_nanalsm1=one/float(nanals-1)
@@ -394,7 +433,7 @@
         allocate(dep(nobsl2))
         do nob=1,nobsl2
            nf=oindex(nob)
-           hdxf(nob,1:nanals)=anal_ob(1:nanals,nf) ! anal_ob is a global array
+           hdxf(nob,1:nanals)=anal_ob_fp(1:nanals,nf) 
            rdiag(nob)=one/oberrvaruse(nf)
            dep(nob)=ob(nf)-ensmean_ob(nf)
         end do
@@ -443,7 +482,7 @@
               nob = indxob_pt(npt,n)
               ! if not vlocal,nn=oblev==1
               if (oblev(nob) == nn .and. oberrvaruse(nob) <= 1.e10_r_single) then
-                 work(1:nanals) = anal_ob(1:nanals,nob)
+                 work(1:nanals) = anal_ob_fp(1:nanals,nob)
                  work2(1:nanals) = ob(nob) - obfit_post(nob) ! ensmean_ob(nob)
                  if(r_kind == kind(1.d0)) then
                     call dgemv('t',nanals,nanals,1.d0,trans,nanals,work,1,1.d0,work2,1)
@@ -488,7 +527,10 @@
 end do ! niter loop
 
 if (update_obspace) deallocate(oblev,indxob_pt,numobsperpt)
-deallocate(anal_ob)
+
+! free shared memory segement, fortran pointer to that memory.
+nullify(anal_ob_fp)
+call MPI_Win_free(shm_win, ierr)
 
 return
 
